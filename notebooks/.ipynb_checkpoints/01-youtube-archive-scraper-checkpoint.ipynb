{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ab1178",
   "metadata": {},
   "source": [
    "### YouTube archive data extraction\n",
    "\n",
    "This notebook extracts data from the `search-history.html`, `watch-history.html` and `my-comments.html` files of a YouTube Archive. You can request a YouTube archive of an account's view and watch history [on Google's Takeout page](https://takeout.google.com/settings/takeout) by selecting the archive you would like to download while logged into the account for which you want the data. This same account will be emailed a download link once the archive is ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42928289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————— libraries built into Python ———————\n",
    "\n",
    "import json # to read json formatted data\n",
    "import csv # to write and read csv\n",
    "import time # to build in wait time for loops\n",
    "import glob # to access file paths\n",
    "\n",
    "# —————— libraries that need to be installed, which you can do via pip ———————\n",
    "\n",
    "from bs4 import BeautifulSoup # to parse HTML, documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "import pandas as pd # to use pandas to process data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3a779",
   "metadata": {},
   "source": [
    "The cells below extracts data from the HTML pages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84117e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Ensure that the path to your file is correct\n",
    "with open(\"../data/youtube-archive/YouTube and YouTube Music/history/search-history.html\") as page:\n",
    "    rows=[]\n",
    "    soup = BeautifulSoup(page,  \"html.parser\")\n",
    "    contents = soup.find(\"body\")\n",
    "    contentlist = contents.find_all( \"div\" , class_=\"outer-cell\")\n",
    "    for content_item in contentlist:\n",
    "        content_cell = content_item.find_all(\"div\" , class_=\"content-cell\")\n",
    "\n",
    "        video_title = content_cell[0].find(\"a\").text if content_cell[0].find(\"a\") != None else \"\"\n",
    "        link = content_cell[0].find(\"a\")[\"href\"]\n",
    "        content_type = content_cell[0].find(\"a\").previous_sibling\n",
    "        date_recorded =  content_cell[0].find_all(\"br\")[-1].next_sibling\n",
    "        meta_data_products = content_cell[-1].find_all(\"br\")[0].next_sibling if content_cell[-1].find_all(\"br\") != None else \"\"\n",
    "        \n",
    "        if \"Details\" in str(content_cell[-1].find_all(\"b\")[1]):\n",
    "            meta_data_details = content_cell[-1].find_all(\"b\")[1].next_sibling.next_sibling\n",
    "        else:\n",
    "            meta_data_details = None\n",
    "        content_text_full = content_cell[0].text if content_cell[0] != None else \"\"\n",
    "        meta_data_full = content_cell[-1].text if content_cell[-1] != None else \"\"\n",
    "\n",
    "        row ={\n",
    "            \"video_title\": video_title,\n",
    "            \"link\": link,\n",
    "            \"content_type\": content_type,\n",
    "            \"date_recorded\": date_recorded,\n",
    "            \"meta_data_products\": meta_data_products,\n",
    "            \"meta_data_details\": meta_data_details,\n",
    "            \"content_text_full\": content_text_full,\n",
    "            \"meta_data_full\": meta_data_full,\n",
    "            \"file\": \"../data/youtube-archive/YouTube and YouTube Music/history/search-history.html\".split(\"/\")[-1]\n",
    "        }\n",
    "\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_history = pd.DataFrame(rows)\n",
    "search_history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_history.to_csv(\"../output/search_history.csv\", encoding='utf-8', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94082920",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82666f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_history[\"meta_data_details\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aadd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_history[\"content_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e22cf",
   "metadata": {},
   "source": [
    "#### This cell extracts data from the watch history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36382b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Ensure that the path to your file is correct\n",
    "with open(\"../data/youtube-archive/YouTube and YouTube Music/history/watch-history.html\") as page:\n",
    "    rows=[]\n",
    "    soup = BeautifulSoup(page,  \"html.parser\")\n",
    "    contents = soup.find(\"body\")\n",
    "    contentlist = contents.find_all( \"div\" , class_=\"outer-cell\")\n",
    "    for content_item in contentlist:\n",
    "        content_cell = content_item.find_all(\"div\" , class_=\"content-cell\")\n",
    "\n",
    "        video_title = content_cell[0].find(\"a\").text if content_cell[0].find(\"a\") != None else \"\"\n",
    "        link = content_cell[0].find(\"a\")[\"href\"] if content_cell[0].find(\"a\") != None else \"\"\n",
    "        content_type = content_cell[0].find(\"a\").previous_sibling  if content_cell[0].find(\"a\") != None else \"\"\n",
    "        date_recorded =  content_cell[0].find_all(\"br\")[-1].next_sibling\n",
    "        meta_data_products = content_cell[-1].find_all(\"br\")[0].next_sibling if content_cell[-1].find_all(\"br\") != None else \"\"\n",
    "        \n",
    "        if \"Details\" in str(content_cell[-1].find_all(\"b\")[1]):\n",
    "            meta_data_details = content_cell[-1].find_all(\"b\")[1].next_sibling.next_sibling\n",
    "        else:\n",
    "            meta_data_details = None\n",
    "        content_text_full = content_cell[0].text if content_cell[0] != None else \"\"\n",
    "        meta_data_full = content_cell[-1].text if content_cell[-1] != None else \"\"\n",
    "\n",
    "        row ={\n",
    "            \"video_title\": video_title,\n",
    "            \"link\": link,\n",
    "            \"date_recorded\": date_recorded,\n",
    "            \"meta_data_products\": meta_data_products,\n",
    "            \"meta_data_details\": meta_data_details,\n",
    "            \"content_text_full\": content_text_full,\n",
    "            \"meta_data_full\": meta_data_full,\n",
    "            \"file\": \"../data/youtube-archive/YouTube and YouTube Music/history/search-history.html\".split(\"/\")[-1]\n",
    "        }\n",
    "\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history = pd.DataFrame(rows)\n",
    "\n",
    "watch_history.to_csv(\"../output/watch_history.csv\", encoding='utf-8', index=False)\n",
    "watch_history.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(watch_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311600e7",
   "metadata": {},
   "source": [
    "#### This cell extracts comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rows = []\n",
    "# Ensure that the path to your file is correct\n",
    "with open(\"../data/youtube-archive/YouTube and YouTube Music/my-comments/my-comments.html\") as page:\n",
    "    rows=[]\n",
    "    soup = BeautifulSoup(page,  \"html.parser\")\n",
    "    comment_container = soup.find(\"ul\")\n",
    "    comment_list = comment_container.find_all( \"li\")\n",
    "    for comment in comment_list: \n",
    "        comment_text = comment.text.split(\"Z.\")[1]\n",
    "        links = comment.find_all(\"a\")\n",
    "        comment_link = links[0]['href']\n",
    "        video_link = links[1][\"href\"]\n",
    "        date = comment.text.split(\"at\")[1].split(\"Z\")[0]\n",
    "        row ={\n",
    "            \"date\":date, \n",
    "            \"comment_link\":comment_link,\n",
    "            \"video_link\":video_link, \n",
    "            \"comment_text\":comment_text\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2193773",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ce89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.DataFrame(rows)\n",
    "comments_df.to_csv(\"../output/comments.csv\", index =False)\n",
    "\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ecf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc04a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
